{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9e1ba39",
   "metadata": {},
   "source": [
    "## Text Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bfc41f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bc8b5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing URL: https://insights.blackcoffer.com/ai-in-healthcare-to-improve-patient-outcomes/. 'NoneType' object has no attribute 'text'\n",
      "Error processing URL: https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/. 'NoneType' object has no attribute 'text'\n",
      "Error processing URL: https://insights.blackcoffer.com/future-of-work-how-ai-has-entered-the-workplace/. 'NoneType' object has no attribute 'text'\n",
      "Error processing URL: https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future/. 'NoneType' object has no attribute 'text'\n",
      "Error processing URL: https://insights.blackcoffer.com/human-rights-outlook/. 'NoneType' object has no attribute 'text'\n",
      "Error processing URL: https://insights.blackcoffer.com/how-voice-search-makes-your-business-a-successful-business/. 'NoneType' object has no attribute 'text'\n",
      "Error processing URL: https://insights.blackcoffer.com/estimating-the-impact-of-covid-19-on-the-world-of-work-3/. 'NoneType' object has no attribute 'text'\n",
      "Error processing URL: https://insights.blackcoffer.com/how-covid-19-is-impacting-payment-preferences/. 'NoneType' object has no attribute 'text'\n",
      "Error processing URL: https://insights.blackcoffer.com/how-will-covid-19-affect-the-world-of-work-2/. 'NoneType' object has no attribute 'text'\n",
      "Error processing URL: https://insights.blackcoffer.com/how-will-covid-19-affect-the-world-of-work-3/. 'NoneType' object has no attribute 'text'\n",
      "Error processing URL: https://insights.blackcoffer.com/ensuring-growth-through-insurance-technology/. 'NoneType' object has no attribute 'text'\n"
     ]
    }
   ],
   "source": [
    "import openpyxl\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Specify the input file path\n",
    "input_file = 'Input.xlsx'\n",
    "\n",
    "# Load the workbook and select the active worksheet\n",
    "workbook = openpyxl.load_workbook(input_file)\n",
    "worksheet = workbook.active\n",
    "\n",
    "# Get the index of the columns containing the link and URL ID\n",
    "link_column = None\n",
    "url_id_column = None\n",
    "for col_idx, cell in enumerate(worksheet[1]):\n",
    "    if cell.value == 'URL':\n",
    "        link_column = col_idx\n",
    "    elif cell.value == 'URL_ID':\n",
    "        url_id_column = col_idx\n",
    "if link_column is None or url_id_column is None:\n",
    "    raise ValueError('Could not find columns for link and URL ID')\n",
    "\n",
    "if not os.path.exists('output'):\n",
    "    os.makedirs('output')\n",
    "\n",
    "# Loop over each row in the worksheet and extract the link and URL ID\n",
    "for row in worksheet.iter_rows(min_row=2, values_only=True):\n",
    "    try:\n",
    "        link = row[link_column]\n",
    "        url_id = row[url_id_column]\n",
    "\n",
    "        # Send a GET request to the URL and save the content to a file\n",
    "        response = requests.get(link)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Extract the title\n",
    "        title_element = soup.find('h1', {'class': 'entry-title'})\n",
    "        title = title_element.text.strip()\n",
    "\n",
    "        # Extract the text content\n",
    "        article_body = soup.find('div', {'class': 'td-post-content tagdiv-type'})\n",
    "        paragraphs = article_body.find_all('p')\n",
    "        text = '\\n'.join([p.text.strip() for p in paragraphs])\n",
    "\n",
    "        # Save the title and text content to a file\n",
    "        with open(os.path.join('output', str(url_id) + '.txt'), 'w', encoding='utf-8') as f:\n",
    "            f.write(title + '\\n\\n' + text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing URL: {link}. {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5210b0b7",
   "metadata": {},
   "source": [
    "Some of the links were not working(Web page not found) So I used try and except to tackle that problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb31c8cc",
   "metadata": {},
   "source": [
    "## Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b4fd1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ERNST', 'YOUNG', 'DELOITTE', 'TOUCHE', 'KPMG', 'PRICEWATERHOUSECOOPERS', 'PRICEWATERHOUSE', 'COOPERS', 'AFGHANI', 'ARIARY']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "directory = r\"C:\\Users\\User\\Downloads\\StopWords\"\n",
    "words_list = []\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    if os.path.isfile(filepath):\n",
    "        # Open the file and read the lines\n",
    "        with open(filepath, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                # Split the line by whitespace and take the first word\n",
    "                first_word = line.split()[0]\n",
    "                # Append the first word to the list\n",
    "                words_list.append(first_word)\n",
    "\n",
    "print(words_list[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bb1f20",
   "metadata": {},
   "source": [
    "Now that we have all the stop words in one list we can just use that and remove the stopwords in the text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86cf2d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chardet\n",
    "\n",
    "directory = r\"C:\\Users\\User\\Downloads\\output\"\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    if os.path.isfile(filepath):\n",
    "        with open(filepath, 'rb') as f:\n",
    "            encoding = chardet.detect(f.read())['encoding']\n",
    "        # Open the file and read the lines\n",
    "        with open(filepath, 'r',encoding=encoding) as file:\n",
    "            lines = file.readlines()\n",
    "        # Open the file again in write mode\n",
    "        with open(filepath, 'w', encoding=encoding) as file:\n",
    "            # Loop through the lines and remove words from the list\n",
    "            for line in lines:\n",
    "                words = line.strip().split()\n",
    "                # Remove words from the list\n",
    "                new_words = [word for word in words if word not in words_list]\n",
    "                # Write the new line to the file\n",
    "                file.write(' '.join(new_words) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7e2d6d",
   "metadata": {},
   "source": [
    "## Creating a Positive and Negative Dictionary of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "793a9aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a+',\n",
       " 'abound',\n",
       " 'abounds',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'accessable',\n",
       " 'accessible',\n",
       " 'acclaim',\n",
       " 'acclaimed',\n",
       " 'acclamation']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_file = r\"C:\\Users\\User\\Downloads\\positive-words.txt\"\n",
    "with open(p_file, 'r') as f:\n",
    "    p = f.readlines()\n",
    "positive = [item.replace('\\n', '') for item in p]\n",
    "positive[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9111a8ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2-faced',\n",
       " '2-faces',\n",
       " 'abnormal',\n",
       " 'abolish',\n",
       " 'abominable',\n",
       " 'abominably',\n",
       " 'abominate',\n",
       " 'abomination',\n",
       " 'abort',\n",
       " 'aborted']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_file = r\"C:\\Users\\User\\Downloads\\negative-words.txt\"\n",
    "with open(n_file, 'r') as f:\n",
    "    n = f.readlines()\n",
    "negative = [item.replace('\\n', '') for item in n]\n",
    "negative[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e7dee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the positive score\n",
    "def calculate_positive_score(text):\n",
    "    words = text.split()\n",
    "    return sum([1 for word in words if word in positive])\n",
    "\n",
    "def calculate_negative_score(text):\n",
    "    words = text.split()\n",
    "    return sum([-1*-1 for word in words if word in negative]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b388ec2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = r\"C:\\Users\\User\\Downloads\\output\"\n",
    "# Specify the input file path\n",
    "input_file = 'Input.xlsx'\n",
    "link = []\n",
    "url_id = []\n",
    "# Load the workbook and select the active worksheet\n",
    "workbook = openpyxl.load_workbook(input_file)\n",
    "worksheet = workbook.active\n",
    "# results = pd.DataFrame(columns=['URL_ID', 'URL', 'POSITIVE SCORE'])\n",
    "for row in worksheet.iter_rows(min_row=2, values_only=True):\n",
    "    link.append(row[link_column])\n",
    "    url_id.append(row[url_id_column])\n",
    "#     results = results.append({'URL_ID': url_id, 'URL':link},ignore_index=True)\n",
    "link = pd.DataFrame(link, columns=['URL'])\n",
    "url_id = pd.DataFrame(url_id, columns=['URL_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "daa580f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_score = []\n",
    "negative_score = []\n",
    "polarity_score = []\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.txt'):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        with open(filepath, 'rb') as f:\n",
    "            encoding = chardet.detect(f.read())['encoding']\n",
    "        with open(filepath, 'r', encoding=encoding) as f:\n",
    "            text = f.read()\n",
    "            positive_score.append(calculate_positive_score(text))\n",
    "            negative_score.append(calculate_negative_score(text))\n",
    "#             polarity_score.append(calculate_polarity(text))\n",
    "positive_score = pd.DataFrame(positive_score)\n",
    "negative_score = pd.DataFrame(negative_score)\n",
    "results = pd.concat([url_id, link, positive_score, negative_score], axis=1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0cc52a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.0</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.0</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.0</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  POSITIVE SCORE  \\\n",
       "0    37.0  https://insights.blackcoffer.com/ai-in-healthc...             3.0   \n",
       "1    38.0  https://insights.blackcoffer.com/what-if-the-c...            23.0   \n",
       "2    39.0  https://insights.blackcoffer.com/what-jobs-wil...             6.0   \n",
       "3    40.0  https://insights.blackcoffer.com/will-machine-...            26.0   \n",
       "4    41.0  https://insights.blackcoffer.com/will-ai-repla...            21.0   \n",
       "\n",
       "   NEGATIVE SCORE  \n",
       "0             2.0  \n",
       "1            37.0  \n",
       "2            22.0  \n",
       "3            48.0  \n",
       "4            31.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.columns = ['URL_ID', 'URL', 'POSITIVE SCORE', 'NEGATIVE SCORE']\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "339ea172",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['POLARITY SCORE'] = (results['POSITIVE SCORE'] - results['NEGATIVE SCORE']) / (results['POSITIVE SCORE'] + results['NEGATIVE SCORE']) * 0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46b0be1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.0</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-2.333333e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.0</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-5.714286e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.0</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-2.972973e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-1.923077e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  POSITIVE SCORE  \\\n",
       "0    37.0  https://insights.blackcoffer.com/ai-in-healthc...             3.0   \n",
       "1    38.0  https://insights.blackcoffer.com/what-if-the-c...            23.0   \n",
       "2    39.0  https://insights.blackcoffer.com/what-jobs-wil...             6.0   \n",
       "3    40.0  https://insights.blackcoffer.com/will-machine-...            26.0   \n",
       "4    41.0  https://insights.blackcoffer.com/will-ai-repla...            21.0   \n",
       "\n",
       "   NEGATIVE SCORE  POLARITY SCORE  \n",
       "0             2.0    2.000000e-07  \n",
       "1            37.0   -2.333333e-07  \n",
       "2            22.0   -5.714286e-07  \n",
       "3            48.0   -2.972973e-07  \n",
       "4            31.0   -1.923077e-07  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fe3ef3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVE SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.0</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000e-07</td>\n",
       "      <td>0.009434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-2.333333e-07</td>\n",
       "      <td>0.113208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.0</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-5.714286e-07</td>\n",
       "      <td>0.052830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.0</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-2.972973e-07</td>\n",
       "      <td>0.139623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-1.923077e-07</td>\n",
       "      <td>0.098113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  POSITIVE SCORE  \\\n",
       "0    37.0  https://insights.blackcoffer.com/ai-in-healthc...             3.0   \n",
       "1    38.0  https://insights.blackcoffer.com/what-if-the-c...            23.0   \n",
       "2    39.0  https://insights.blackcoffer.com/what-jobs-wil...             6.0   \n",
       "3    40.0  https://insights.blackcoffer.com/will-machine-...            26.0   \n",
       "4    41.0  https://insights.blackcoffer.com/will-ai-repla...            21.0   \n",
       "\n",
       "   NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVE SCORE  \n",
       "0             2.0    2.000000e-07          0.009434  \n",
       "1            37.0   -2.333333e-07          0.113208  \n",
       "2            22.0   -5.714286e-07          0.052830  \n",
       "3            48.0   -2.972973e-07          0.139623  \n",
       "4            31.0   -1.923077e-07          0.098113  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.txt'):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        with open(filepath, 'rb') as f:\n",
    "            encoding = chardet.detect(f.read())['encoding']\n",
    "        with open(filepath, 'r', encoding=encoding) as f:\n",
    "            text = f.read()\n",
    "            words = text.split()\n",
    "        results['SUBJECTIVE SCORE'] = (results['POSITIVE SCORE'] + results['NEGATIVE SCORE']) / (len(words) + 0.000001) \n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "525d4314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "directory = r\"C:\\Users\\User\\Downloads\\output\"\n",
    "avg_sentence_length = []\n",
    "\n",
    "# Loop through each file in the folder\n",
    "for filename in os.listdir(directory):\n",
    "    # Check if the file is a text file\n",
    "    if filename.endswith('.txt'):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        with open(filepath, 'rb') as f:\n",
    "            encoding = chardet.detect(f.read())['encoding']\n",
    "        # Read the contents of the file\n",
    "        with open(os.path.join(directory, filename), 'r', encoding=encoding) as file:\n",
    "            text = file.read()\n",
    "        \n",
    "        # Tokenize the text into sentences\n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        \n",
    "        # Count the number of sentences in the file\n",
    "        sentence_count = len(sentences)\n",
    "        \n",
    "        # Count the number of words in the file\n",
    "        words = nltk.word_tokenize(text)\n",
    "        word_count = len(words)\n",
    "        \n",
    "        # Calculate the average sentence length\n",
    "        avg_length = word_count / sentence_count\n",
    "        \n",
    "        # Append the average sentence length to the overall list\n",
    "        avg_sentence_length.append(avg_length)\n",
    "\n",
    "# Create a DataFrame from the average sentence length list\n",
    "df = pd.DataFrame({'Average Sentence Length': avg_sentence_length})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88823fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['AVG SENTENCE LENGTH'] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2aef9899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_syllables(word):\n",
    "    vowels = \"aeiouy\"\n",
    "    count = 0\n",
    "    for index in range(len(word)):\n",
    "        if word[index] in vowels:\n",
    "            if index == 0:\n",
    "                count += 1\n",
    "            elif word[index - 1] not in vowels:\n",
    "                count += 1\n",
    "    if word.endswith(\"e\"):\n",
    "        count -= 1\n",
    "    if count == 0:\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "def find_complex_words(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        encoding = chardet.detect(f.read())['encoding']\n",
    "    with open(file_path, \"r\", encoding=encoding) as file:\n",
    "        text = file.read()\n",
    "    words = re.findall(r\"\\b\\w+\\b\", text)\n",
    "    complex_words = []\n",
    "    for word in words:\n",
    "        if count_syllables(word) > 2:\n",
    "            complex_words.append(word)\n",
    "    return complex_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "638ccfb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: syllables in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (1.0.7)\n",
      "Requirement already satisfied: cmudict<2.0.0,>=1.0.11 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from syllables) (1.0.13)\n",
      "Requirement already satisfied: importlib-metadata<6.0.0,>=5.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from syllables) (5.2.0)\n",
      "Requirement already satisfied: importlib-resources<6.0.0,>=5.10.1 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from cmudict<2.0.0,>=1.0.11->syllables) (5.12.0)\n",
      "Requirement already satisfied: zipp>=0.5 in e:\\anaconda\\lib\\site-packages (from importlib-metadata<6.0.0,>=5.1.0->syllables) (3.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9dccba16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import syllables\n",
    "directory = r\"C:\\Users\\User\\Downloads\\output\"\n",
    "percent_complex_words = []\n",
    "\n",
    "# Loop through each file in the folder\n",
    "for filename in os.listdir(directory):\n",
    "    # Check if the file is a text file\n",
    "    if filename.endswith('.txt'):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        with open(filepath, 'rb') as f:\n",
    "            encoding = chardet.detect(f.read())['encoding']\n",
    "        # Read the contents of the file\n",
    "        with open(os.path.join(directory, filename), 'r', encoding=encoding) as file:\n",
    "            text = file.read()\n",
    "        \n",
    "        # Split the text into words\n",
    "        words = text.split()\n",
    "        \n",
    "        # Count the number of words in the file\n",
    "        word_count = len(words)\n",
    "        \n",
    "        # Count the number of complex words in the file\n",
    "        complex_word_count = sum(1 for word in words if syllables.estimate(str(word)) > 2)\n",
    "        \n",
    "        # Calculate the percentage of complex words\n",
    "        percent_complex = (complex_word_count / word_count) * 100\n",
    "        \n",
    "        # Append the percentage of complex words to the overall list\n",
    "        percent_complex_words.append(percent_complex)\n",
    "\n",
    "# Create a DataFrame from the percentage of complex words list\n",
    "df = pd.DataFrame({'Percent Complex Words': percent_complex_words})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b23e4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['PERCENTAGE OF COMPLEX WORDS'] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c008793",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['FOG INDEX'] = 0.4 * (results['AVG SENTENCE LENGTH'] + results['PERCENTAGE OF COMPLEX WORDS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3e77f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "directory = r\"C:\\Users\\User\\Downloads\\output\"\n",
    "avg_words_per_sentence = []\n",
    "\n",
    "# Loop through each file in the folder\n",
    "for filename in os.listdir(directory):\n",
    "    # Check if the file is a text file\n",
    "    if filename.endswith('.txt'):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        with open(filepath, 'rb') as f:\n",
    "            encoding = chardet.detect(f.read())['encoding']\n",
    "        # Read the contents of the file\n",
    "        with open(os.path.join(directory, filename), 'r',encoding=encoding) as file:\n",
    "            text = file.read()\n",
    "        \n",
    "        # Tokenize the text into sentences\n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        \n",
    "        # Count the total number of sentences in the file\n",
    "        total_sentence_count = len(sentences)\n",
    "        \n",
    "        # Count the total number of words in the file\n",
    "        words = nltk.word_tokenize(text)\n",
    "        total_word_count = len(words)\n",
    "        \n",
    "        # Calculate the average number of words per sentence\n",
    "        avg_words = total_word_count / total_sentence_count\n",
    "        \n",
    "        # Append the average number of words per sentence to the overall list\n",
    "        avg_words_per_sentence.append(avg_words)\n",
    "\n",
    "# Create a DataFrame from the average number of words per sentence list\n",
    "df = pd.DataFrame({'Average Words per Sentence': avg_words_per_sentence})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "452141f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['AVERAGE NUMBER OF WORDS PER SENTENCE'] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "062c3e46",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVE SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVERAGE NUMBER OF WORDS PER SENTENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.0</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000e-07</td>\n",
       "      <td>0.009434</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>14.560000</td>\n",
       "      <td>11.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-2.333333e-07</td>\n",
       "      <td>0.113208</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>35.528596</td>\n",
       "      <td>18.931438</td>\n",
       "      <td>11.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.0</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-5.714286e-07</td>\n",
       "      <td>0.052830</td>\n",
       "      <td>13.457143</td>\n",
       "      <td>36.266667</td>\n",
       "      <td>19.889524</td>\n",
       "      <td>13.457143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.0</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-2.972973e-07</td>\n",
       "      <td>0.139623</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>44.354839</td>\n",
       "      <td>23.453935</td>\n",
       "      <td>14.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-1.923077e-07</td>\n",
       "      <td>0.098113</td>\n",
       "      <td>15.868421</td>\n",
       "      <td>35.010482</td>\n",
       "      <td>20.351561</td>\n",
       "      <td>15.868421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  POSITIVE SCORE  \\\n",
       "0    37.0  https://insights.blackcoffer.com/ai-in-healthc...             3.0   \n",
       "1    38.0  https://insights.blackcoffer.com/what-if-the-c...            23.0   \n",
       "2    39.0  https://insights.blackcoffer.com/what-jobs-wil...             6.0   \n",
       "3    40.0  https://insights.blackcoffer.com/will-machine-...            26.0   \n",
       "4    41.0  https://insights.blackcoffer.com/will-ai-repla...            21.0   \n",
       "\n",
       "   NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVE SCORE  AVG SENTENCE LENGTH  \\\n",
       "0             2.0    2.000000e-07          0.009434            11.400000   \n",
       "1            37.0   -2.333333e-07          0.113208            11.800000   \n",
       "2            22.0   -5.714286e-07          0.052830            13.457143   \n",
       "3            48.0   -2.972973e-07          0.139623            14.280000   \n",
       "4            31.0   -1.923077e-07          0.098113            15.868421   \n",
       "\n",
       "   PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
       "0                    25.000000  14.560000   \n",
       "1                    35.528596  18.931438   \n",
       "2                    36.266667  19.889524   \n",
       "3                    44.354839  23.453935   \n",
       "4                    35.010482  20.351561   \n",
       "\n",
       "   AVERAGE NUMBER OF WORDS PER SENTENCE  \n",
       "0                             11.400000  \n",
       "1                             11.800000  \n",
       "2                             13.457143  \n",
       "3                             14.280000  \n",
       "4                             15.868421  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2643898",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# Define a regular expression pattern to match syllables\n",
    "# We'll use a simple pattern here that just counts vowels\n",
    "syllable_pattern = re.compile(\"[aeiouy]+\", re.IGNORECASE)\n",
    "\n",
    "# Define a function to count the number of syllables in a word\n",
    "def count_syllables(word):\n",
    "    return len(syllable_pattern.findall(word))\n",
    "\n",
    "# Define a function to count the number of complex words in a file\n",
    "def count_complex_words(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        encoding = chardet.detect(f.read())['encoding']\n",
    "    # Open the file for reading\n",
    "    with open(filename, \"r\",encoding=encoding) as file:\n",
    "        # Read the file contents into a string\n",
    "        contents = file.read()\n",
    "        # Split the contents into words\n",
    "        words = contents.split()\n",
    "        # Count the number of complex words\n",
    "        complex_word_count = sum(1 for word in words if count_syllables(str(word)) > 2)\n",
    "        # Return the count\n",
    "        return complex_word_count\n",
    "\n",
    "# Define a function to count the number of complex words in a folder\n",
    "def count_complex_words_in_folder(folder_path):\n",
    "    # Initialize the results list\n",
    "    result = []\n",
    "    # Iterate over all files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # If the file is a text file, count the complex words\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            complex_word_count = count_complex_words(file_path)\n",
    "            # Add the result to the list\n",
    "            result.append({\"filename\": filename, \"complex_word_count\": complex_word_count})\n",
    "    # Create a DataFrame from the results\n",
    "    df = pd.DataFrame(result)\n",
    "    # Return the DataFrame\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94b49ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r\"C:\\Users\\User\\Downloads\\output\"\n",
    "df = count_complex_words_in_folder(folder_path)\n",
    "results['COMPLEX WORD COUNT'] = df['complex_word_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab3ccb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Word Count\n",
      "0            92\n",
      "1           577\n",
      "2           375\n",
      "3           620\n",
      "4           477\n",
      "..          ...\n",
      "99          569\n",
      "100         996\n",
      "101         509\n",
      "102         595\n",
      "103         530\n",
      "\n",
      "[104 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "directory = r\"C:\\Users\\User\\Downloads\\output\"\n",
    "word_counts = []\n",
    "\n",
    "# Loop through each file in the folder\n",
    "for filename in os.listdir(directory):\n",
    "    # Check if the file is a text file\n",
    "    if filename.endswith('.txt'):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        with open(filepath, 'rb') as f:\n",
    "            encoding = chardet.detect(f.read())['encoding']\n",
    "        # Read the contents of the file\n",
    "        with open(os.path.join(directory, filename), 'r', encoding=encoding) as file:\n",
    "            text = file.read()\n",
    "        \n",
    "        # Split the text into words\n",
    "        words = text.split()\n",
    "        \n",
    "        # Count the number of words in the file\n",
    "        word_count = len(words)\n",
    "        \n",
    "        # Append the word count to the overall list\n",
    "        word_counts.append(word_count)\n",
    "\n",
    "# Create a DataFrame from the word count list\n",
    "df = pd.DataFrame({'Word Count': word_counts})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af7c46c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['WORD COUNT'] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7fb82319",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVE SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVERAGE NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.0</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000e-07</td>\n",
       "      <td>0.009434</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>14.560000</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>23.0</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-2.333333e-07</td>\n",
       "      <td>0.113208</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>35.528596</td>\n",
       "      <td>18.931438</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>205.0</td>\n",
       "      <td>577.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.0</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-5.714286e-07</td>\n",
       "      <td>0.052830</td>\n",
       "      <td>13.457143</td>\n",
       "      <td>36.266667</td>\n",
       "      <td>19.889524</td>\n",
       "      <td>13.457143</td>\n",
       "      <td>136.0</td>\n",
       "      <td>375.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.0</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-2.972973e-07</td>\n",
       "      <td>0.139623</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>44.354839</td>\n",
       "      <td>23.453935</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>275.0</td>\n",
       "      <td>620.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-1.923077e-07</td>\n",
       "      <td>0.098113</td>\n",
       "      <td>15.868421</td>\n",
       "      <td>35.010482</td>\n",
       "      <td>20.351561</td>\n",
       "      <td>15.868421</td>\n",
       "      <td>167.0</td>\n",
       "      <td>477.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  POSITIVE SCORE  \\\n",
       "0    37.0  https://insights.blackcoffer.com/ai-in-healthc...             3.0   \n",
       "1    38.0  https://insights.blackcoffer.com/what-if-the-c...            23.0   \n",
       "2    39.0  https://insights.blackcoffer.com/what-jobs-wil...             6.0   \n",
       "3    40.0  https://insights.blackcoffer.com/will-machine-...            26.0   \n",
       "4    41.0  https://insights.blackcoffer.com/will-ai-repla...            21.0   \n",
       "\n",
       "   NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVE SCORE  AVG SENTENCE LENGTH  \\\n",
       "0             2.0    2.000000e-07          0.009434            11.400000   \n",
       "1            37.0   -2.333333e-07          0.113208            11.800000   \n",
       "2            22.0   -5.714286e-07          0.052830            13.457143   \n",
       "3            48.0   -2.972973e-07          0.139623            14.280000   \n",
       "4            31.0   -1.923077e-07          0.098113            15.868421   \n",
       "\n",
       "   PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
       "0                    25.000000  14.560000   \n",
       "1                    35.528596  18.931438   \n",
       "2                    36.266667  19.889524   \n",
       "3                    44.354839  23.453935   \n",
       "4                    35.010482  20.351561   \n",
       "\n",
       "   AVERAGE NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \n",
       "0                             11.400000                23.0        92.0  \n",
       "1                             11.800000               205.0       577.0  \n",
       "2                             13.457143               136.0       375.0  \n",
       "3                             14.280000               275.0       620.0  \n",
       "4                             15.868421               167.0       477.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7e9f3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyphen in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyphen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1da24a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Syllable Counts\n",
      "0    [1, 2, 2, 1, 2, 2, 2, 5, 2, 2, 1, 1, 1, 1, 2, ...\n",
      "1    [2, 2, 2, 2, 1, 2, 3, 3, 1, 1, 2, 4, 3, 1, 2, ...\n",
      "2    [1, 4, 4, 1, 3, 3, 2, 1, 2, 1, 3, 1, 1, 2, 1, ...\n",
      "3    [1, 3, 4, 4, 4, 3, 2, 3, 1, 2, 3, 2, 3, 1, 2, ...\n",
      "4    [2, 3, 3, 2, 1, 4, 3, 2, 1, 1, 1, 1, 1, 2, 1, ...\n",
      "..                                                 ...\n",
      "99   [2, 2, 1, 1, 1, 1, 1, 1, 4, 2, 1, 1, 1, 3, 1, ...\n",
      "100  [2, 2, 2, 2, 1, 2, 3, 2, 2, 1, 2, 1, 4, 3, 3, ...\n",
      "101  [3, 2, 4, 2, 1, 2, 1, 2, 1, 6, 1, 1, 1, 2, 1, ...\n",
      "102  [2, 2, 1, 1, 2, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "103  [4, 2, 3, 1, 1, 3, 5, 3, 2, 4, 1, 2, 1, 1, 2, ...\n",
      "\n",
      "[104 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pyphen\n",
    "\n",
    "# Create a Pyphen object for English language\n",
    "dic = pyphen.Pyphen(lang='en')\n",
    "\n",
    "# Path to the folder containing the text files\n",
    "folder_path = r\"C:\\Users\\User\\Downloads\\output\"\n",
    "\n",
    "# List to store the syllable count per file\n",
    "syllable_counts = []\n",
    "\n",
    "# Loop through each file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    # Check if the file is a text file\n",
    "    if filename.endswith('.txt'):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        with open(filepath, 'rb') as f:\n",
    "            encoding = chardet.detect(f.read())['encoding']\n",
    "        # Read the contents of the file\n",
    "        with open(os.path.join(folder_path, filename), 'r', encoding=encoding) as file:\n",
    "            text = file.read()\n",
    "        \n",
    "        # Split the text into words\n",
    "        words = text.split()\n",
    "        \n",
    "        # List to store the syllable count per word in the file\n",
    "        syllables_per_word = []\n",
    "        \n",
    "        # Loop through each word in the file\n",
    "        for word in words:\n",
    "            # Count the syllables of the word\n",
    "            syllables = len(dic.inserted(word).split('-'))\n",
    "            \n",
    "            # Append the syllable count to the list\n",
    "            syllables_per_word.append(syllables)\n",
    "        \n",
    "        # Append the syllable count list to the overall list\n",
    "        syllable_counts.append(syllables_per_word)\n",
    "\n",
    "# Create a DataFrame from the syllable count list\n",
    "syllable_count = pd.DataFrame({'Syllable Counts': syllable_counts})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(syllable_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db253c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['SYLLABLE PER WORD'] = syllable_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0848cb5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVE SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVERAGE NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.0</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000e-07</td>\n",
       "      <td>0.009434</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>14.560000</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>23.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>[1, 2, 2, 1, 2, 2, 2, 5, 2, 2, 1, 1, 1, 1, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-2.333333e-07</td>\n",
       "      <td>0.113208</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>35.528596</td>\n",
       "      <td>18.931438</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>205.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>[2, 2, 2, 2, 1, 2, 3, 3, 1, 1, 2, 4, 3, 1, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.0</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-5.714286e-07</td>\n",
       "      <td>0.052830</td>\n",
       "      <td>13.457143</td>\n",
       "      <td>36.266667</td>\n",
       "      <td>19.889524</td>\n",
       "      <td>13.457143</td>\n",
       "      <td>136.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>[1, 4, 4, 1, 3, 3, 2, 1, 2, 1, 3, 1, 1, 2, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.0</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-2.972973e-07</td>\n",
       "      <td>0.139623</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>44.354839</td>\n",
       "      <td>23.453935</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>275.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>[1, 3, 4, 4, 4, 3, 2, 3, 1, 2, 3, 2, 3, 1, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-1.923077e-07</td>\n",
       "      <td>0.098113</td>\n",
       "      <td>15.868421</td>\n",
       "      <td>35.010482</td>\n",
       "      <td>20.351561</td>\n",
       "      <td>15.868421</td>\n",
       "      <td>167.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>[2, 3, 3, 2, 1, 4, 3, 2, 1, 1, 1, 1, 1, 2, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  POSITIVE SCORE  \\\n",
       "0    37.0  https://insights.blackcoffer.com/ai-in-healthc...             3.0   \n",
       "1    38.0  https://insights.blackcoffer.com/what-if-the-c...            23.0   \n",
       "2    39.0  https://insights.blackcoffer.com/what-jobs-wil...             6.0   \n",
       "3    40.0  https://insights.blackcoffer.com/will-machine-...            26.0   \n",
       "4    41.0  https://insights.blackcoffer.com/will-ai-repla...            21.0   \n",
       "\n",
       "   NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVE SCORE  AVG SENTENCE LENGTH  \\\n",
       "0             2.0    2.000000e-07          0.009434            11.400000   \n",
       "1            37.0   -2.333333e-07          0.113208            11.800000   \n",
       "2            22.0   -5.714286e-07          0.052830            13.457143   \n",
       "3            48.0   -2.972973e-07          0.139623            14.280000   \n",
       "4            31.0   -1.923077e-07          0.098113            15.868421   \n",
       "\n",
       "   PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
       "0                    25.000000  14.560000   \n",
       "1                    35.528596  18.931438   \n",
       "2                    36.266667  19.889524   \n",
       "3                    44.354839  23.453935   \n",
       "4                    35.010482  20.351561   \n",
       "\n",
       "   AVERAGE NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
       "0                             11.400000                23.0        92.0   \n",
       "1                             11.800000               205.0       577.0   \n",
       "2                             13.457143               136.0       375.0   \n",
       "3                             14.280000               275.0       620.0   \n",
       "4                             15.868421               167.0       477.0   \n",
       "\n",
       "                                   SYLLABLE PER WORD  \n",
       "0  [1, 2, 2, 1, 2, 2, 2, 5, 2, 2, 1, 1, 1, 1, 2, ...  \n",
       "1  [2, 2, 2, 2, 1, 2, 3, 3, 1, 1, 2, 4, 3, 1, 2, ...  \n",
       "2  [1, 4, 4, 1, 3, 3, 2, 1, 2, 1, 3, 1, 1, 2, 1, ...  \n",
       "3  [1, 3, 4, 4, 4, 3, 2, 3, 1, 2, 3, 2, 3, 1, 2, ...  \n",
       "4  [2, 3, 3, 2, 1, 4, 3, 2, 1, 1, 1, 1, 1, 2, 1, ...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b5e9e3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store the word counts per file\n",
    "word_counts = []\n",
    "\n",
    "# Loop through each file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    # Check if the file is a text file\n",
    "    if filename.endswith('.txt'):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        with open(filepath, 'rb') as f:\n",
    "            encoding = chardet.detect(f.read())['encoding']\n",
    "        # Read the contents of the file\n",
    "        with open(os.path.join(folder_path, filename), 'r',encoding=encoding) as file:\n",
    "            text = file.read()\n",
    "        \n",
    "        # Split the text into words\n",
    "        words = text.split()\n",
    "        \n",
    "        # Initialize counters for each word\n",
    "        i_count = 0\n",
    "        we_count = 0\n",
    "        my_count = 0\n",
    "        ours_count = 0\n",
    "        us_count = 0\n",
    "        \n",
    "        # Loop through each word in the file\n",
    "        for word in words:\n",
    "            # Check if the word is one of the target words\n",
    "            if word.lower() == 'i':\n",
    "                i_count += 1\n",
    "            elif word.lower() == 'we':\n",
    "                we_count += 1\n",
    "            elif word.lower() == 'my':\n",
    "                my_count += 1\n",
    "            elif word.lower() == 'ours':\n",
    "                ours_count += 1\n",
    "            elif word.lower() == 'us' and (words.index(word) == 0 or words[words.index(word) - 1].lower() != 'united'):\n",
    "                us_count += 1\n",
    "        \n",
    "        # Append the word counts to the overall list\n",
    "        word_counts.append([i_count, we_count, my_count, ours_count, us_count])\n",
    "\n",
    "# Create a DataFrame from the word count list\n",
    "df = pd.DataFrame({'Word Counts': word_counts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b5630a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['PERSONAL PRONOUNS'] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3620717c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Average Word Length\n",
      "0               6.163043\n",
      "1               6.603120\n",
      "2               6.581333\n",
      "3               7.216129\n",
      "4               6.748428\n",
      "..                   ...\n",
      "99              6.820738\n",
      "100             6.993976\n",
      "101             7.007859\n",
      "102             6.786555\n",
      "103             6.966038\n",
      "\n",
      "[104 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "avg_word_lengths = []\n",
    "\n",
    "# Loop through each file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    # Check if the file is a text file\n",
    "    if filename.endswith('.txt'):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        with open(filepath, 'rb') as f:\n",
    "            encoding = chardet.detect(f.read())['encoding']\n",
    "        # Read the contents of the file\n",
    "        with open(os.path.join(folder_path, filename), 'r', encoding=encoding) as file:\n",
    "            text = file.read()\n",
    "        \n",
    "        # Split the text into words\n",
    "        words = text.split()\n",
    "        \n",
    "        # Calculate the sum of the total number of characters in each word\n",
    "        total_char_count = sum(len(word) for word in words)\n",
    "        \n",
    "        # Calculate the total number of words in the file\n",
    "        total_word_count = len(words)\n",
    "        \n",
    "        # Calculate the average word length\n",
    "        avg_word_length = total_char_count / total_word_count\n",
    "        \n",
    "        # Append the average word length to the overall list\n",
    "        avg_word_lengths.append(avg_word_length)\n",
    "\n",
    "# Create a DataFrame from the average word length list\n",
    "df = pd.DataFrame({'Average Word Length': avg_word_lengths})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7188ab6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['AVG WORD LENGTH'] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e5fa23ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVE SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVERAGE NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.0</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000e-07</td>\n",
       "      <td>0.009434</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>14.560000</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>23.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>[1, 2, 2, 1, 2, 2, 2, 5, 2, 2, 1, 1, 1, 1, 2, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>6.163043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-2.333333e-07</td>\n",
       "      <td>0.113208</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>35.528596</td>\n",
       "      <td>18.931438</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>205.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>[2, 2, 2, 2, 1, 2, 3, 3, 1, 1, 2, 4, 3, 1, 2, ...</td>\n",
       "      <td>[0, 2, 0, 0, 0]</td>\n",
       "      <td>6.603120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.0</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-5.714286e-07</td>\n",
       "      <td>0.052830</td>\n",
       "      <td>13.457143</td>\n",
       "      <td>36.266667</td>\n",
       "      <td>19.889524</td>\n",
       "      <td>13.457143</td>\n",
       "      <td>136.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>[1, 4, 4, 1, 3, 3, 2, 1, 2, 1, 3, 1, 1, 2, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>6.581333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.0</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-2.972973e-07</td>\n",
       "      <td>0.139623</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>44.354839</td>\n",
       "      <td>23.453935</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>275.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>[1, 3, 4, 4, 4, 3, 2, 3, 1, 2, 3, 2, 3, 1, 2, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>7.216129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-1.923077e-07</td>\n",
       "      <td>0.098113</td>\n",
       "      <td>15.868421</td>\n",
       "      <td>35.010482</td>\n",
       "      <td>20.351561</td>\n",
       "      <td>15.868421</td>\n",
       "      <td>167.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>[2, 3, 3, 2, 1, 4, 3, 2, 1, 1, 1, 1, 1, 2, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>6.748428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  POSITIVE SCORE  \\\n",
       "0    37.0  https://insights.blackcoffer.com/ai-in-healthc...             3.0   \n",
       "1    38.0  https://insights.blackcoffer.com/what-if-the-c...            23.0   \n",
       "2    39.0  https://insights.blackcoffer.com/what-jobs-wil...             6.0   \n",
       "3    40.0  https://insights.blackcoffer.com/will-machine-...            26.0   \n",
       "4    41.0  https://insights.blackcoffer.com/will-ai-repla...            21.0   \n",
       "\n",
       "   NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVE SCORE  AVG SENTENCE LENGTH  \\\n",
       "0             2.0    2.000000e-07          0.009434            11.400000   \n",
       "1            37.0   -2.333333e-07          0.113208            11.800000   \n",
       "2            22.0   -5.714286e-07          0.052830            13.457143   \n",
       "3            48.0   -2.972973e-07          0.139623            14.280000   \n",
       "4            31.0   -1.923077e-07          0.098113            15.868421   \n",
       "\n",
       "   PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
       "0                    25.000000  14.560000   \n",
       "1                    35.528596  18.931438   \n",
       "2                    36.266667  19.889524   \n",
       "3                    44.354839  23.453935   \n",
       "4                    35.010482  20.351561   \n",
       "\n",
       "   AVERAGE NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
       "0                             11.400000                23.0        92.0   \n",
       "1                             11.800000               205.0       577.0   \n",
       "2                             13.457143               136.0       375.0   \n",
       "3                             14.280000               275.0       620.0   \n",
       "4                             15.868421               167.0       477.0   \n",
       "\n",
       "                                   SYLLABLE PER WORD PERSONAL PRONOUNS  \\\n",
       "0  [1, 2, 2, 1, 2, 2, 2, 5, 2, 2, 1, 1, 1, 1, 2, ...   [0, 0, 0, 0, 0]   \n",
       "1  [2, 2, 2, 2, 1, 2, 3, 3, 1, 1, 2, 4, 3, 1, 2, ...   [0, 2, 0, 0, 0]   \n",
       "2  [1, 4, 4, 1, 3, 3, 2, 1, 2, 1, 3, 1, 1, 2, 1, ...   [0, 0, 0, 0, 0]   \n",
       "3  [1, 3, 4, 4, 4, 3, 2, 3, 1, 2, 3, 2, 3, 1, 2, ...   [0, 0, 0, 0, 0]   \n",
       "4  [2, 3, 3, 2, 1, 4, 3, 2, 1, 1, 1, 1, 1, 2, 1, ...   [0, 0, 0, 0, 0]   \n",
       "\n",
       "   AVG WORD LENGTH  \n",
       "0         6.163043  \n",
       "1         6.603120  \n",
       "2         6.581333  \n",
       "3         7.216129  \n",
       "4         6.748428  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0de54228",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efda851e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
